x <- [−262, -265, -256, -267, -270, -272, -272.4, -272.7, -272.8, -272.9]
x <- c(−262, -265, -256, -267, -270, -272, -272.4, -272.7, -272.8, -272.9)
y = c(0.315, 0.202, 0.204 , 0.620, 0.715 , 0.935
, 0.957
, 0.906
, 0.985
, 0.987
)
plot(x, y)
sum ( (x-mean(x))*(y-mean(y))  )
sum ( (x-mean(x))*(x-mean(x))  )
sum ( (x-mean(x))*(y-mean(y))  ) / sum ( (x-mean(x))*(x-mean(x))  )
mean(y) + 0.05282894 * mean(x)
mean(y) - 0.05282894 * mean(x)
mean(x)
mean(y)
sum ( (x-mean(x))*(x-mean(x))  )
1/  sum ( (x-mean(x))*(x-mean(x))  )
sd(y)
sum ( (y-mean(y))*(y-mean(y))  ) - ( sum ( (x-mean(x))*(y-mean(y))  ) / sum ( (x-mean(x))*(x-mean(x))  ) ) * sum ( (x-mean(x))*(y-mean(y))  )
sum( (y - mean(y))^2 )
length(x)
(sum ( (y-mean(y))*(y-mean(y))  ) - ( sum ( (x-mean(x))*(y-mean(y))  ) / sum ( (x-mean(x))*(x-mean(x))  ) ) * sum ( (x-mean(x))*(y-mean(y))  ) ) /8
0.1422518/8
-0.0528 / sqrt( 0.00335*0.0177 )
q()
setwd( paste( getwd(), "/ClassificationEmotionModels_ISEAR", sep = '' ) )
getwd()
setwd( paste( getwd(), "/Sebastian/ClassificationEmotionModels_ISEAR", sep = '' ) )
source('R code/data_loader.R')
source('R code/models/NaiveBayes.R')
install.packages("tidytext")
library(tidytext)
sentiments
installed.packages("dplyr")
installed.packages("stringr")
installed.packages("janeaustenr")
library(dplyr)
library(stringr)
library(janeaustenr)
test <- austen_books()
summary(test)
test$text
test$book
test <- austen_books() %>%  group_by(book)
summary(test)
test <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup()
summary(test)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
summary(tidy_books)
View(tidy_books)
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE)
jane_austen_sentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
library(tidyr)
jane_austen_sentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
View(jane_austen_sentiment)
ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
pride_prejudice <- tidy_books %>%
filter(book == "Pride & Prejudice")
afinn <- pride_prejudice %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(score)) %>%
mutate(method = "AFINN")
pride_prejudice %>%
inner_join(get_sentiments("afinn"))
pride_prejudice %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80)
pride_prejudice %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(score))
pride_prejudice %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(score)) %>%
mutate(method = "AFINN")
summary(afinn)
afinn$method
summary(afinn)
summary(afinn$method)
bing_and_nrc <- bind_rows(pride_prejudice %>%
inner_join(get_sentiments("bing")) %>%
mutate(method = "Bing et al."),
pride_prejudice %>%
inner_join(get_sentiments("nrc") %>%
filter(sentiment %in% c("positive",
"negative"))) %>%
mutate(method = "NRC")) %>%
count(method, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
bind_rows(afinn,
bing_and_nrc) %>%
ggplot(aes(index, sentiment, fill = method)) +
geom_col(show.legend = FALSE) +
facet_wrap(~method, ncol = 1, scales = "free_y")
data <- get.bagOfWords.allPartData("py_isear_dataset/isear.csv")
source('R code/data_loader.R')
data <- get.bagOfWords.allPartData("py_isear_dataset/isear.csv")
data <- getPreproc.Data.ISEAR("py_isear_dataset/isear.csv")
levels( data$EMOT ) <- list("1" = "joy", "2" = "fear", "3" = "anger", "4" = "sadness", "5" = "disgust", "6" = "shame", "7" = "guilt")
data$EMOT <- as.numeric(data$EMOT)
mat <- bag.of.words(data$SIT)
source('R code/data_loader.R')
mat <- bag.of.words(data$SIT)
dim(mat)
mat.s <- scale(mat)
summary(mat.s)
str(mat.s)
str(mat[mat == 0])
str(mat[mat == 0,])
all?
?
3
all(mat[1,]== 0)
all(mat[2,]== 0)
all(mat[3,]== 0)
summary(mat[1,])
row_sub <- apply(mat, 1, function(row) all(row ==0 ))
dim(mat)
dim(row_sub)
dim(mat[row_sub,])
dim(mat[!row_sub,])
which(row_sub)
summary(mat[518,])
data$SIT[518,]
data$SIT[518]
data.or <- getData.ISEAR("py_isear_dataset/isear.csv")
data.or$SIT[518]
data <- preproccess.ISEAR(data.or)
data$SIT[518]
data.or$SIT[518]
data.or$SIT[1]
data$SIT[1]
data$SIT[2]
data.or$SIT[2]
data$SIT[519]
data.or$SIT[519]
data.or$SIT[517]
data$SIT[517]
data$SIT[516]
data.or$SIT[516]
source('R code/data_loader.R')
data.or <- getData.ISEAR("py_isear_dataset/isear.csv")
data <- preproccess.ISEAR(data.or)
data.or$SIT[516]
data$SIT[516]
isear.docs <- Corpus(VectorSource(data.or$SIT))
summary(isear.docs)
length(isear.docs)
length(data.or)
length(data.or$SIT)
isear.docs$`516`
isear.docs$516
isear.docs$"516"
isear.docs["516"]
isear.docs["516"]$`1`
isear.docs["516"]["1"]
inspect(isear.docs[1])
inspect(isear.docs[516])
isear.docs <- tm_map(isear.docs, content_transformer(removeNumbers)) # Remove numbers
inspect(isear.docs[516])
isear.docs <- tm_map(isear.docs, content_transformer(tolower)) # Transform words to lower
inspect(isear.docs[516])
isear.docs <- tm_map(isear.docs, content_transformer(removeWords), stopwords("english")) # Remove english common stopwords e.g "the", "is", "of", etc
inspect(isear.docs[516])
isear.docs <- tm_map(isear.docs, content_transformer(removePunctuation)) # Remove punctuations
inspect(isear.docs[516])
isear.docs <- tm_map(isear.docs, stripWhitespace) # Eliminate extra white spaces
inspect(isear.docs[516])
isear.docs <- tm_map(isear.docs, stemDocument) # Text stemming (reduces words to their root form)
inspect(isear.docs[516])
# GET STEMMING SENTENCES BACK TO ISEAR.DATA
isear.data$SIT <- sapply(isear.docs, identity)
test <- sapply(isear.docs, identity)
test[516]
length(test)
source('R code/data_loader.R')
data.or <- getData.ISEAR("py_isear_dataset/isear.csv")
data <- preproccess.ISEAR(data.or)
data$SIT[516]
data$EMOT[516]
data.or$SIT[516]
data.or$EMOT[516]
length(data.or$SIT)
length(data$SIT)
data.or$SIT[517]
data$SIT[517]
data$SIT[516]
data$SIT[515]
data$EMOT[515]
data.or$EMOT[517]
dim(mat[row_sub,])
dim(mat[!row_sub,])
source("R code/data_loader.R")
data <- get.bagOfWords.allPartData("py_isear_dataset/isear.csv")
mat.s[row_sub,]
mat.s[row_sub,][0]
mat.s[row_sub,][1]
mat.s[row_sub,][2]
mat.s[row_sub,][3]
mat.s[row_sub,][4]
mat.s[row_sub,][5]
dim(data[[1]])
source("R code/data_loader.R")
data <- get.bagOfWords.allPartData("py_isear_dataset/isear.csv")
data.or <- getData.ISEAR("py_isear_dataset/isear.csv")
data <- preproccess.ISEAR(data.or)
isear.docs <- DocumentTermMatrix(Corpus(VectorSource(data$SIT)))
removeSparseTerms(isear.docs, 0.999)
dim(data$SIT)
length(data$SIT)
dim(mat)
length(row_sub)
source("R code/data_loader.R")
data <- get.bagOfWords.allPartData("py_isear_dataset/isear.csv")
data.or <- getData.ISEAR("py_isear_dataset/isear.csv")
data <- preproccess.ISEAR(data.or)
levels( data$EMOT ) <- list("1" = "joy", "2" = "fear", "3" = "anger", "4" = "sadness", "5" = "disgust", "6" = "shame", "7" = "guilt")
data$EMOT <- as.numeric(data$EMOT)
mat <- bag.of.words(data$SIT)
# Delete all rows that have all columns in zero and normalize
row_sub <- apply(mat, 1, function(row) all(row ==0 ))
length(row_sub)
mat <- mat[!row_sub,]
mat <- scale(mat)
data$EMOT[!row_sub,]
length(data$EMOT)
length(data$EMOT[-1,])
source("R code/data_loader.R")
data <- get.bagOfWords.allPartData("py_isear_dataset/isear.csv")
str(data[[1]])
head(data[[1]]$labels_model)
levels(data[[1]]$EMOT) <- list("joy" = "1", "fear" = "2", "anger" = "3", "sadness" = "4", "disgust" = "5", "shame" = "6", "guilt" = "7")
levels(data[[1]]$labels_model) <- list("joy" = "1", "fear" = "2", "anger" = "3", "sadness" = "4", "disgust" = "5", "shame" = "6", "guilt" = "7")
head(data[[1]]$labels_model)
data <- get.bagOfWords.allPartData("py_isear_dataset/isear.csv")
levels(data[[1]]$labels_model) <- list("joy" = "1", "fear" = "2", "anger" = "3", "sadness" = "4", "disgust" = "5", "shame" = "6", "guilt" = "7")
table( data[[1]]$labels_model )
source("R code/data_loader.R")
source("R code/data_loader.R")
data <- get.bagOfWords.allPartData("py_isear_dataset/isear.csv")
levels(data[[1]]$labels_model) <- list("joy" = "1", "fear" = "2", "anger" = "3", "sadness" = "4", "disgust" = "5", "shame" = "6", "guilt" = "7")
table( data[[1]]$labels_model )
table( data[[2]]$labels_model )
levels(data[[2]]$labels_model) <- list("joy" = "1", "fear" = "2", "anger" = "3", "sadness" = "4", "disgust" = "5", "shame" = "6", "guilt" = "7")
table( data[[2]]$labels_model ) + table( data[[1]]$labels_model )
source("R code/models/NaiveBayes.R")
model.naivebayes <- naiveBayes( labels_model ~ ., data = data[[1]])
pred <- predict(model.naivebayes, data[[1]])
pred <- predict(model.naivebayes, data[[1]], type = 'raw')
table( data[[2]]$labels_model )
str(model.naivebayes)
model.naivebayes
model.naivebayes$call
pred <- predict(model.naivebayes, data[[1]], type = 'raw')
model.naivebayes <- train.naiveBayes(data[[1]])
pred <- predict.naiveBayes(model.naivebayes, data[[1]])
source("R code/models/NaiveBayes.R")
model.naivebayes <- train.naiveBayes(data[[1]])
pred <- predict.naiveBayes(model.naivebayes, data[[1]])
length(data[[1]][ ,"labels_model" ])
length(data[[1]][ ,-"labels_model" ])
length(data[[1]][ ,-c("labels_model") ])
test <- subset( data[[1]], select = -labels_model )
pred <- predict.naiveBayes(model.naivebayes, test)
dim(test)
dim(data[[1]])
source("R code/models/NaiveBayes.R")
pred <- predict.naiveBayes(model.naivebayes, test)
rm("predict")
